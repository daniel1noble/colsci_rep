---
fontsize: 12pt
geometry: margin=0.75in
output: pdf_document
---

#The transparency of methods-reporting in studies measuring biological colouration

Rhiannon L. Dalrymple^1,6^, Daniel W. A. Noble^2,6^, James C. O’Hanlon ^2,6^, Kate D. L. Umbers^3,4,6^, Thomas E. White^2,6^, Daniel B. Zurek^5,6^

^1^ Evolution & Ecology Research Centre, School of Biological, Earth and Environmental Sciences, University of New South Wales, Kensington, NSW, Australia, 2022 ^2^ Department of Biological Sciences, Macquarie University, North Ryde, NSW, Australia, 2109 ^3^ School of Biological Sciences, University of Wollongong, Wollongong, NSW, Australia 2252 ^4^ Centre for Evolutionary Biology, University of Western Australia, Crawley, WA, Australia 6008 ^5^ Department of Biological Sciences, University of Pittsburgh, Pittsburgh, PA, USA, 15260

^6^ Authors contributed equally and are presented in alphabetical order

Corresponding Author:

Keywords: #colsci, visual ecology, spectrophotometry, tetrahedral color space, quantum catch, pigment, structural color, thermoregulation, signaling, PAVO, colormetrics, visual modeling, melanism, sexual selection.

##Abstract

##Introduction
Since Thayer (1909), Poulton (1890) and Wallace (YEAR) generations of biologists have endeavored to explain the mechanisms and functions of animal and plant coloration. For these biologists, identifying best practice in measuring color and color pattern and in determining how other species see colour has been a great challenge. Over the past 150 years biologists, both independently and in collaboration with physicists and chemists, have developed a range of techniques used to measure and analyse animal and plant coloration including spectrophotometry (also called spectroradiometry, spectroscopy ETC), photography and visual modeling.  

The application of spectrophotometry to questions in ecology and evolution revolutionized the field (Dyck 1966). Before the widespread use of spectrophotometry researchers assigned categorical color descriptions, arbitrary rankings or scores (e.g. Aldrich & James, 1991; Wheelwright & Janson, 1985) or matched paint swatches or munsell chip ratings based on their own visual assessment (e.g. Key and Day 1954, Burtt 1986). Although no doubt applied carefully, these techniques limited progress in field. For example, many researchers designed color assessment methods specifically for their projects (e.g. Alrich and James 1991) rendering data by different researchers incomparable. This was/is especially problematic when different measurement techniques are used on the same species (e,g, refXXX vs ref XXX). Also, human vision, blind to ultraviolet wavelengths, is inherently different to most other animals such as avian and reptilian tetrachromats and insect trichromats, (Bennett 1994, Douglas and Jeffrey 2014); human perception of color, and variation therein, is not only biologically irrelevant to most systems, but it can lead to erroneous conclusions (Bennett, Cuthill and Norris 1994, Endler 1990).   

Measuring reflectance spectra is now a reasonably inexpensive and convenient technique. Spectrophotometry allows the capture of quantitative and arguably repeatable data and has been rapidly taken up by researchers the field. However one drawback to spectrophotometry, is the ease with which erroneous data can be captured if attention is not paid to finer details of spectrum capture. For example, the angle from which spectra are taken (Santos & Lumeij, 2007), consistent calibration of light and dark standards, the distance between light source and object, the expectations of the researcher and the size, shape, glossiness or iridescence of the specimen (Andersson and Prager, 2006, Schaefer et al., 2008, Kemp, Reznick & Grether, 2008, Meadows et al 2011), can all contribute to potentially skewed data or alter results. Experience, guidance and objectivity are necessary to ensure data are consistent and representative of the subject and to ensure repeatability, conditions under which data were collected must be reported exactly.  

In conjunction with spectrophotometry, digital photography is increasingly being implemented in color quantification. High-resolution cameras are now inexpensive and portable, allow instantaneous sampling of multiple colour patches, and can produce highly repeatable images (McKay 2013). The main challenges for gathering and using color data from photographs are ensure correct standardization methods such as linearization and consistent lighting (Stevens et al. 2007; ref Dariella Whitiyev 2014’s paper). Crucially, most digital cameras used in color science are consumer products designed for human visual color space and hardware modifications for ultraviolet and infrared imaging are necessary (e.g. Chiao et al. 2009, McKay 2013), making photography complementary, rather than superior to spectrophotometry. 

Expansion in the availability of objective methods for the measurement of color has been matched by advances in theory and analysis. In particular, the development of sensory models has produced significant insights into the way in which colorful stimuli are perceived (Bennett et al 1994, Chittka 1992, Endler & Mielke 2005, Vorobyev & Osorio 1998). Where the receptor sensitivities of an animal’s visual system are known, the physiological response of that animal’s visual system when viewing a given color can be predicted. Physiological sensory models of animal vision have been developed to model the perception of bees (e.g. Chittka, 1992), flies (e.g. Troje, 1993), birds (e.g. Endler & Mielke, 2005), moths (e.g. Chuang, Yang & Tso, 2007), frogs (REF), crabs (REF) and snakes (e.g. Maan & Cummings, 2012).  

Sensory models typically attempt to describe the subjective perception of color or brightness information as a function of an object’s reflectance, the ambient illumination, and a receiver’s sensory system (eg. Endler & Mielke 2005, Vorobyev et al. 1998). Furthermore, an animal’s ability to distinguish between reflectance spectra can then be predicted based on the differential responses of a visual system to varying reflectance spectra. This approach enables researchers to move beyond purely quantitative comparisons of reflectance spectra and adopt biologically relevant perspectives of signal receivers to test/formulate hypotheses.  
Although relatively easy to implement and potentially powerful, sensory models are built on multiple assumptions about the way in which stimuli are visually and cognitively processed that can dramatically shape the results of a given analysis (Lind & Kelber 2009; Pike 2012). For example, Vorobyev et al.’s (1998; 2001) widely used receptor-noise model requires researchers to specify the form of receptor quantum catches (i.e. raw versus log-transformed), the existence of any color correction mechanism (e.g. von Kries), as well as the photoreceptor signal-to-noise ratios, their relative densities, and the type of noise predominating (i.e. neural and/or receptor noise). These data are only available for a small number of model species (e.g. honeybees) and thus assumptions and extrapolations are necessary when models are applied to related species. Unless the biological rationale underlying every parameter choice is clearly understood, justified, and reported, such analyses may become ineffective, especially when comparing results between studies (Pike 2012).  

Since the repeatability and transparency of science is paramount, it is imperative that we regularly and constructively reflect on our own practices (Peng, 2009; Alsheikh-Ali et al. 2011; Sandve et al YEAR). The potential for detrimental subjectivity in color measurement and the mathematical opacity of visual models for the average colour scienctist means that, as in any field, is it critical that methods are reported rigorously. Methods reporting should ideally have well defined standards such that sufficient detail is provided to allow comprehensive peer review, precise replication, cross-study comparison and data sharing (REF data sharing papers, Ask Rob Lanfear). The aims of this paper are to (a) review methods reporting in papers published on colour in 2013 from 20 top tier journals and (b) provide a set of recommendations for best-practice in reporting on the most common methods. Our best hope is that this instructional provides a useful set of guidelines to improve the reproducibility and transparency of studies on color.

##Ideal reporting in colour studies 

We developed a list of metrics we deemed critical to be reported for reproducibility of color methods and analysis loosely based on Andersson and Prager (2006) and Montgomerie (2006) (Table 1 and 2). These included quantitative methods including spectrophotometric and photographic techniques (as in REF), but not qualitative methods such as the use of Munsell chips or paint swatches (as in REF). For visual modeling techniques we characterized a set of criteria required for reproducing the analysis (Table 2). 

##What is reporting like in the literature? 

To determine the current state of methods reporting in the field we searched for papers from 2013 in 23 top color science journals (_Animal Behaviour_, _Behavioral Ecology_, _Journal of Experimental Biology_, _Biology Letters_, _Proceedings of the Royal Society B: Biological Sciences_, _Biological Journal of the Linnean Society_, _Ethology_, _The American Naturalist_, _Ecology Letters_, _Journal of Evolutionary Biology_, _American Journal of Botany_, _Evology and Evolution_, _Oikos_, _Ecology_, _Journal of Ecology_, _Behavioral Ecology and Sociobiology_, _Current Zoology_, _Naturwissenschaften_, _New Phytologist_, _PLoS ONE_, _Evolution_, _Functional Ecology_, _Ethology_). For each of the journals, we used the Boolean search terms 'colour*', 'color*' or 'spectra*' and searched for these in the title or abstract from each of the journal home pages. We read the titles and abstracts of each paper and included only those papers that explicitly used either a spectrophotometer or camera to quantify colour signals. We excluded papers that were: 1) review papers; 2) methodological papers; 3) papers quantifying colour pattern; and 4) papers taking microspectrophotometric measurments of retinal absorbance. To review the large number of papers returned from the searches, journals were haphazardly divided up between the authors. In order to reduce the risk of observer bias in our scoring, papers were read and reassessed by a total of three authors. Any discrepancies between the assessor scores were discussed and agreed upon prior to analysis. We then tabulated what details of the methods were reported against our criteria.
 
Our search returned a total of 216 papers, however, only `r nrow(coldat)` met our criteria and were included in the final analysis. Overall, `r specs+both` studies used a spectrophotometer to measure color, while `r cam+both` used a camera. Of these studies, `r both` quantified color using both a spectrophotometer and a camera. Reporting of the make and model of the spectrophotometer and camera was high (Figure 1 - Specs = `r round(specModel, digits = 2)`% and Cameras = `r round(camModel, digits = 2)`%), however, only `r round(CamLight, digits = 2)`%  and `r round(specLight, digits = 2)`% of camera and spec studies reported a light source. In addition, the number of reflectance spectra and pixels averaged were only reported in `r round(specAVG, digits = 2)`% and `r round(camAVG, digits = 2)`% of the studies, respectively. Surprisingly, of the spec studies, dark standards were only reported in `r round(drk_std, digits = 2)`% of the studies, while white standards were reported in `r round(white_stdspec, digits = 2)`%. Studies quantifying spectral reflectance also often did not report the integration time of the spectrophotmeter (`r round(intTime, digits = 2)`%) or the angle (`r round(angle, digits = 2)`%) or the distance (`r round(dist, digits = 2)`%) the probe was from the color patch. 
	
Analysis varied across studies but, overall `r analysisType[1]` analyzed their data by generating colormetric (brightness, hue, chroma) variables whereas `r analysisType[4]` used visual models, `r analysisType[2]` used multiple analysis types (e.g. visual model and colourmetric) and `r analysisType[3]` did other forms of analysis (e.g. RGB, PCA's, GLMMs etc.). Of the studies quantifying colour using spectral reflectance curves `r analysisTypeSpec[1]` used colormetric measures, `r analysisTypeSpec[2]` used multiple analyses, `r analysisTypeSpec[4]` used visual models and `r analysisTypeSpec[3]` used other forms of analysis. Studies using colormetric measurements defined their measure of brightness, hue and/or chroma in `r round(col_def, digits = 2)`% of the studies. 

Most studies using visual models analysed their data using receptor noise models (`r vismod_type[3]` of `r sum(vismod_type)` studies) while others used hexagon (`r vismod_type[1]` studies) or tcs (`r vismod_type[4]` studies). Case specific models were used in `r vismod_type[2]` cases. Overall, `r round(prop_irrad, digits =2)`% reported the type of irradiance, `r round(prop_spvismod, digits = 2)`% the species used in their visual model and `r round(propvis_mod_param, digits = 2)`% made explicit mention of the parameters they used (i.e. cone densities, neural vs quantum catchs etc.) in their methods. The background used in visual models was reported `r round(prop_bkg, digits = 2)`% of the time. The type of visual noise authors assumed was reported in `r round(prop_noise, digits = 2)`% of the studies. In addition, explicit mention of the type of quantum catche (`r round(prop_qcatch, digits = 2)`%) or whether photoreceptor adaptation (`r round(prop_adap, digits = 2)`%) was accounted for in visual models was not common. 

While some of the values reported above seem alarming, it is important to note that papers often made reference to previous work for various methods (`r round(ref_stud, digits = 2)`%) and so these figures are slightly liberal given that referenced work may have comprehensively covered some of these criteria. Despite this, many of the studies that did not reference previous work were lacking in their reporting of many aspects of our criteria suggesting the need for more comprehensive reporting of data collection and analysis methods within studies. 

```{r, barplot, eval = TRUE, echo = FALSE, fig.ext = "pdf", fig.cap = "Figure 1"}

par(mfrow=c(1,2))
props   <- c(specModel, camModel, specLight, CamLight, drk_std, white_stdspec, specAVG, camAVG)
N_props <- c((specs+both), (cam+both), length(DatSpec$light_source), length(DatCam$light_source), length(DatSpec$dark_std), length(DatSpec$white_stdspec), length(DatSpec$specpix_avg), length(DatCam$specpix_avg))

names   <- c("Spec", "Cam", "Spec L", "Pix Avg"," Cam L"," Wt Std", "Spec Avg", "Drk Std")
dat     <- t(arrange(data.frame(props, N_props), props, decreasing = TRUE))
colnames(dat) <- names

barplot(dat[1,], ylim = c(0,100), ylab = "Percentage of studies reporting criteria", xlab = "Criteria", col = "gray", space = 0.30, cex.names = 0.72, mgp = c(2.5,0.5,0), cex.axis = 1.2, cex.lab = 1.5) -> bp.out
abline(h = 0, lwd = 2)
text(dat[2,], x = bp.out, y = 98)
text(paste(round(dat[1,], digits = 0), "%", sep = ""), x = bp.out, y = round(dat[1,], digits = 0)*0.5)
mtext("a)", adj = -0.10, padj = -1, cex = 2)


props_analy   <- c(prop_irrad, prop_spvismod, propvis_mod_param, prop_adap, prop_qcatch, prop_bkg, prop_noise)

N_props_analy <- c(length(DatSpec$irrad_type[! is.na(DatSpec$irrad_type)]), length(DatSpec$vis_mod_sp[! is.na(DatSpec$vis_mod_sp)]), length(DatSpec$vis_mod_param[! is.na(DatSpec$vis_mod_param)]), length(DatSpec$vis_mod_adapt[! is.na(DatSpec$vis_mod_adapt)]), length(DatSpec$vis_mod_qcatch[! is.na(DatSpec$vis_mod_qcatch)]), length(DatSpec$vis_mod_bkg[! is.na(DatSpec$vis_mod_bkg)]), length(DatSpec$vis_mod_noise_type[! is.na(DatSpec$vis_mod_noise_type)]))

dat_analy     <- t(arrange(data.frame(props_analy, N_props_analy), props_analy, decreasing = TRUE))

names_analy   <- c("SpRep", "Bkg", "Irrad", "Qcatch","Noise"," ChrAdapt", "ModPara")
colnames(dat_analy) <- names_analy

barplot(dat_analy[1,], ylim = c(0,100), ylab = "Percentage of studies reporting criteria", xlab = "Criteria", col = "gray", space = 0.30, cex.names = 0.72, mgp = c(2.5,0.5,0), cex.axis = 1.2, cex.lab = 1.5) -> bp.out
abline(h = 0, lwd = 2)
text(dat_analy[2,], x = bp.out, y = 98)
text(paste(round(dat_analy[1,], digits = 0), "%", sep = ""), x = bp.out, y = round(dat_analy[1,], digits = 0)*0.5)
mtext("b)", adj = -0.10, padj = -1, cex = 2)

```























