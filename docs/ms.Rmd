# Reproducible research in the study of biological colouration

Thomas E. White^2,7^, Rhiannon L. Dalrymple^1,7^, Daniel W. A. Noble^2,7^, James C. O’Hanlon ^2,7^, Daniel B. Zurek^5,7^, Kate D. L. Umbers^3,4,6,7^

^1^ Evolution & Ecology Research Centre, School of Biological, Earth and Environmental Sciences, University of New South Wales, Kensington, NSW, Australia, 2022 ^2^ Department of Biological Sciences, Macquarie University, North Ryde, NSW, Australia, 2109 ^3^ School of Biological Sciences, University of Wollongong, Wollongong, NSW, Austrlaia 2252 ^4^ Centre for Evolutionary Biology, University of Western Australia, Crawley, WA, Australia 6008 ^5^ Department of Biological Sciences, University of Pittsburgh, Pittsburgh, PA, USA, 15260 ^6^ School of Science and Health, University of Western Sydney Hawkesbury, NSW, Australia 2751

^7^ Authors contributed equally and are presented in random order

Corresponding Author: 

Thomas E. White, Department of Biological Sciences, Macquarie University, North Ryde, NSW, Australia, 2109

Phone: +61 2 9850 6279

E-mail: thomas.white@mq.edu.au

Keywords: spectrometry, photography, visual ecology, pigment, structural colour, visual modelling, methods 

Article type: Commentary

Word count:

Number of figures: 

Number of tables: 2

Data archiving:

\newpage

## Introduction

The study of colour in nature has generated insights into fundamental evolutionary and ecological processes, and research into colour traits is a rapidly growing field [@kelber_spectral_2010]. Resurgent interest in biological colouration has in large part been driven by the increased availability of key technologies, including spectrometry and photography, and concurrent advances in methods for analysing colour data, such as visual models [@endler_comparing_2005; @stevens_using_2007; @kelber_animal_2003]. While these developments are positive for the field, the increasingly complex analyses being run on ever greater amounts of data heighten the need for comprehensive methods reporting and proper data management [@alsheikh_public_2011; @nekrutenko_next_2012].      

Replication and transparency lie at the heart of the scientific enterprise. Beyond simply allowing independent verification of results, reproducible research ensures greater comparability between studies and provides a foundation for testing new ideas and methods [@whitlock_data_2011; @van_trouble_2011; @piwowar_sharing_2007]. A study may be considered truly reproducible when it satisfies three broad criteria: (i) methods are reported completely, (ii) data are publicly available and archived, and (iii) analysis code is publicly available, such that the chain of modification of raw data is documented and preserved. While completely reproducible research [e.g. @fitzjohn_much_2014] is a laudable goal, the considerable demands it imposes on researchers means that it will often, in practice, be unattainable. Nevertheless, even partial reproducibility through the relatively simple practices of complete methods reporting and public data archiving is of tremendous value.     

Our aim was to explore the state of reproducibility in studies of biological colouration, and to outline ways in which it may be improved. We begin by briefly outlining some of the most common methods for studying biological colouration, with an emphasis on the way in which their subtle complexity can dramatically shape results. We then present a set of guidelines for the comprehensive reporting of methods, and we analyse a subset of the literature against these criteria to assess the state of methods reporting in studies of biological colouration. We also assess the availability of publicly archived data and code, and suggest some useful tools for increasing the reproducibility of colour trait research more broadly.  

## Measuring colour

Generations of biologists have endeavoured to explain the mechanisms and functions of animal and plant colouration [@thayer_concealing_1909; @poulton_colours_1890; @wallace_natural_1891], and uncovering best practices in measuring colour has been a great challenge. The application of spectrometry (also called spectroradiometry, or spectrophotometry) to questions of biological colouration revolutionized the field [@dyck_determination_1966]. Now relatively inexpensive and convenient, spectrometry allows for the rapid capture of quantitative data, and has been widely adopted as standard across the field [@andersson_quantifying_2006]. Digital photography is also increasingly being used to quantify biological colouration [@stevens_using_2007], as high-resolution cameras are inexpensive and allow for the rapid, repeatable sampling of multiple colour patches [@mckay_use_2013]. 

Subtle variation in the application of these common methods can significantly alter the resulting data. When using spectrometry, for example, the angle from which spectra are collected [@santos_strong_2007], the calibration of light and dark standards, the distance between light source and surface, and the size, shape, glossiness or iridescence of the specimen will all directly affect the recorded spectra [@andersson_quantifying_2006; @kemp_ornamental_2008; @meadows_quantifying_2011; @schaefer_birds_2008]. Equally, the main challenge for gathering colour data from photographs is ensuring standardization against nonlinear responses to light intensity, biases towards particular wavebands, and inconsistent lighting [@stevens_using_2007]. Also, most digital cameras used for the measurement of biological colouration are consumer products designed for the human visual system. Thus hardware modifications for ultraviolet and infra-red imaging are often necessary [e.g. @stevens_colour_2013]. 

Expansion in the availability of objective methods for the measurement of colour has been matched by advances in theory and analysis. In particular, the development of visual models has enabled researchers to move beyond purely quantitative comparisons of reflectance spectra and adopt more biologically relevant perspectives when defining and testing hypotheses [@chittka_colour_1992; @endler_comparing_2005; @vorobyev_receptor_1998]. Visual models typically attempt to describe the reception and early-stage processing of colour information as a function of an object’s reflectance, the ambient illumination, and a receiver’s sensory system [e.g. @endler_comparing_2005; @vorobyev_receptor_1998]. Although relatively easy to implement, visual models are built on multiple assumptions about the way in which stimuli are processed that can dramatically shape the results of a given analysis [@lind_avian_2009; @pike_preserving_2012]. For example, Vorobyev et al.’s [-@vorobyev_receptor_1998; -@vorobyev_colour_2001] widely used receptor-noise model requires researchers to specify the form of receptor quantum catches (i.e. raw versus transformed), the use of any colour constancy mechanism (e.g. von Kries), as well as the photoreceptor signal-to-noise ratios, their relative densities, and the type of noise predominating (i.e. neural and/or receptor noise). These data are only available for a small number of species, such as humans and honeybees, and so assumptions and extrapolations are necessary when models are applied to other species. Unless the biological rationale underlying every parameter choice is clearly understood, justified, and reported, such analyses may become ineffective, especially when comparing results between studies [@pike_preserving_2012].  

The comprehensive reporting of methods is a simple and crucial step in ensuring research is reproducible. Accordingly, we developed a list of essential information about the capture (Table 1) and analysis (Table 2) of colour data that should ideally be reported. Analytical techniques are diverse, mathematically complex, and are being developed rapidly [@kelber_spectral_2010]. Speedy progress means that a deep understanding of common methods can quickly outstrip working knowledge for the average researcher. As a consequence, the subtle complexity of many analytical techniques is often overlooked by empiricists, which leads to critical methodological information not being reported. Our guidelines for reporting the details of colour analyses (Table 2) thus cover two broad, common methods: colourimetric (or 'spectral') analyses, and visual modelling. These tables present the framework for our subsequent analysis of methods reporting in the literature.

## Assessing reporting and reproducibility

To assess the current state of reproducibility in the field we searched papers from 2013 in 22 leading journals: _American Journal of Botany_, _The American Naturalist_, _Animal Behaviour_, _Behavioral Ecology_, _Behavioral Ecology and Sociobiology_, _Biological Journal of the Linnean Society_, _Biology Letters_, _Current Zoology_, _Ecology_, _Ecology and Evolution_, _Ecology Letters_, _Ethology_, _Evolution_, _Functional Ecology_, _Journal of Ecology_, _The Journal of Evolutionary Biology_, _The Journal of Experimental Biology_, _Naturwissenschaften_, _New Phytologist_, _Oikos_, _PLoS ONE_, _Proceedings of the Royal Society B: Biological Sciences_. On each of the journals' homepages, we used the Boolean phrase 'colour\*' or 'color\*' or 'spectra\*' to search the title or abstract. To review the 216 papers returned from our search, journals were haphazardly divided up between the authors. We excluded review papers, methodological papers, papers quantifying colour patterns rather than the chromatic properties of a colour patch, and studies taking micro-spectrometric measurements of retinal absorbance. The final set of `r nrow(coldat)` papers included only those that used either a spectrometer or camera to quantify colouration. In order to reduce the risk of observer bias in our assessment, each paper included in the final set was read and reassessed by three authors. Any discrepancies between assessor scores were discussed and resolved prior to analysis. We then tabulated what details of the methods were reported against our suggested criteria (Tables 1 and 2), and recorded whether data (in either a 'raw' or 'processed' form) and/or any code were publicly available. The data along with analysis script can be found on github (http://dx.doi.org/10.5281/zenodo.13245). We have kept the papers used in our dataset anonymous as our aim is to explore the general question of repeatability in the field and not single out particular studies. 

## Methods reporting in colour studies 

_Reproducibility of data collection_

Overall, `r specs+both` studies used a spectrometer to measure colour, while `r cam+both` used a camera. Of these studies, `r both` quantified colour using both a spectrometer and a camera. Reporting of the make and model of the spectrometer and camera was high (Figure 1, spectrometers = `r round(specModel, digits = 1)`% and cameras = `r round(camModel, digits = 1)`%), however, only `r round(propCam_fin["prop_light_source"], digits = 1)`%  and `r round(propSpec_fin["prop_light_source"], digits = 1)`% of camera and spectrometer studies reported a light source. The number of reflectance spectra and pixels averaged were only reported in `r round(propSpec_fin["prop_specpix_avg"], digits = 1)`% and `r round(propCam_fin["prop_specpix_avg"], digits = 1)`% of studies, respectively. Surprisingly, dark standards were only reported in `r round(propSpec_fin["prop_dark_std"], digits = 1)`% of the spectrometer studies, while white standards were reported in `r round(propSpec_fin["prop_white_stdspec"], digits = 1)`%. Studies quantifying spectral reflectance often did not report the integration time of the spectrophotmeter (`r round(propSpec_fin["prop_int_time"], digits = 1)`%), or the angle of the optical probe relative to the surface (`r round(propSpec_fin["prop_spec_angle"], digits = 1)`%) or distance (`r round(propSpec_fin["prop_spec_dist"], digits = 1)`%) the probe was held from the measurement surface. 
	
_Reproducibility of analyses_

The types of analysis varied across studies. Overall `r analysisType[1]` papers generated colourimetric variables [i.e. 'spectral' measures of hue, saturation, and/or brightness; @montgomerie_analyzing_2006] whereas `r analysisType[4]` used visual models, `r analysisType[2]` used both colourimetrics and visual models, and `r analysisType[3]` used other forms of analysis (e.g. purely statistical analyses, such as principle component analysis on reflectance spectra). Of the studies quantifying colour using spectral reflectance, `r analysisTypeSpec[1]` used colourimetric measures, `r analysisTypeSpec[2]` used multiple analyses, `r analysisTypeSpec[4]` used visual models and `r analysisTypeSpec[3]` used other forms of analysis. Studies using colourimetric measurements defined their measure of brightness, hue and/or chroma in `r round(col_def, digits = 1)`% of the studies. 

Most studies using visual models analysed their data using receptor-noise models (`r vismod_type[3]` of `r sum(vismod_type)` studies), while others used the colour hexagon (`r vismod_type[1]` studies), or a tetrahedral colour space (`r vismod_type[4]` studies). Case specific models were used in `r vismod_type[2]` papers. Of visual modelling papers, `r round(propSpec_fin["prop_irrad_type"], digits =2)`% reported the type of irradiance when necessary, `r round(propSpec_fin["prop_vis_mod_sp"], digits = 1)`% the species modelled as a receiver. The background used in visual models was reported `r round(propSpec_fin["prop_vis_mod_bkg"], digits = 1)`% of the time. The type of receptor noise modelled was reported in only `r round(propSpec_fin["prop_vis_mod_noise_type"], digits = 1)`% of the studies. Explicit mention of the type of quantum catch (`r round(propSpec_fin["prop_vis_mod_qcatch"], digits = 1)`% of studies), or whether photoreceptor adaptation (`r round(propSpec_fin["prop_vis_mod_adapt"], digits = 1)`%) was modelled, was not common. 

_How to increase transparency_

While some of the figures reported above seem alarming, it is important to note that around one-third of papers (`r round(ref_stud, digits = 1)`%) made reference to previous work for various methods. This means that our above figures are slightly liberal given that the referenced works may have comprehensively covered some of these criteria. Despite this, two-thirds of the studies did not reference previous work, and were missing important methodological details. In particular, the light source - sample - probe geometry should be standard reporting for all studies using spectrometry. Visual models were regularly used to analyse spectral data. However, there were many important aspects of the analysis that were seldom reported, including the type of quantum catch used, whether photoreceptor adaptation was modelled and the type of neural noise used in receptor-noise models. Photoreceptor densities should also be reported where possible even if using standard avian photorecptor densities, as all of these parameters have important consequences for downstream analysis and, hence, the reproducibility of colour trait quantification [e.g. @kemp_ornamental_2008; @santos_comparison_2007]. We also recommend the presentation of spectra where possible as these figures allow for the rapid assessment of the nature and quality of the data, independent of downstream processing. We found that only `r round(propSpec_fin["prop_refl_fig"], digits = 1)`% of studies using spectral reflectance data had such a figure. Although not considered in our analysis, we also recommend that authors explicitly outline the biological justification underlying their choices for data capture and analysis. 

## The public availability of data and code

Of the `r nrow(coldat)` studies analysed, `r round((data["raw"]/sum(data))*100, digits = 1)`% publicly provided the raw underlying data, `r round((data["proc"]/sum(data))*100, digits = 1)`% provided data in a pre-processed form, and `r round((data["none"]/sum(data))*100, digits = 1)`% of studies did not provide any publicly accessible data. The paucity of data being made available post-publication in studies of biological colouration is in line with other fields [@drew_lost_2013; @vines_mandated_2013; @wolkovich_advances_2012], including the broader field of animal behaviour [@caetano_forgotten_2014]. There is evidence, however, that this trend is shifting as funding agencies and publishers increasingly mandate the release of data [@whitlock_data_2010]. The clearest benefit of open access to data is that it allows researchers to build upon previous work for the testing and refinement of new ideas and methods. This is particularly relevant in the study of colour traits, where new methods for analysing colour data are regularly developed [e.g. @allen_analyzing_2013; @endler_framework_2012; @stoddard_pattern_2014]. More generally, the provision of open data may also foster collaborations as researchers draw upon existing work [@whitlock_data_2011], and increased data sharing has been shown to positively correlate with citations [@piwowar_sharing_2007]. Given the increasing rate of retractions, there is also impetus for researchers to maintain credibility through transparency [@steen_retractions_2010; @van_trouble_2011; @wicherts_willingness_2011]. We thus encourage researchers to publicly archive data in as raw a form as possible (e.g. individual reflectance spectra), to maximise its utility. Public data repositories such as figshare and dryad allow the permanent archival of data as citable research objects, and the preparation of data for publication is often straightforward [@whitlock_data_2011]. The use of modest data embargoes and appropriate licenses can help to ensure that original authors are able to make the best use of data, and are subsequently credited, though we acknowledge that tensions over data-sharing exist [discussed in @roche_troubleshooting_2014].
 
None of the included studies linked to any form of code, which is not surprising given the popularity of graphical-user-interface (GUI) based statistical and colour-analytical software [e.g. AVICOL; @gomez_avicol_2006]. Here we simply note that there are several advantages to moving away from a GUI-based to a programming workflow, in spite of the initial time investment required. Programming languages such as Python [@van_python_1995] and R [@R_program], for example, are free, open-source, and are host to communities of developers that continuously build and implement analytical tools.  Indeed, tools specifically for the analysis of colour data already exist [e.g. the package 'pavo' for R; @maia_pavo_2013]. Programming languages are flexible by nature, which allows individual researchers to rapidly explore new methods as they are published, and methods developers to implement their analyses to potentially increase the reach and impact of their work. A significant advantage of programmatic analyses is that analysis scripts, when properly curated, represent a complete documented history of a study's methods. The chain of modification of raw data may thus be preserved, both for researchers revisiting their own work in the future and for other scientists looking to build directly on the results of previous studies.  

## Conclusions

Our review of the recent literature highlights some significant impediments to reproducibility in the study of biological colouration. The simplest step towards reproducible research is through the comprehensive reporting of methods, yet crucial methodological information is often unreported (Fig. 1). We found that the types of light sources, numbers of pixels or spectra averaged, the distance and angle of the spectrometers optical probe relative to the measurement surface and collector, and types of standards used (i.e. white and black reference samples) are under-reported (Fig. 1). Visual models were regularly used to analyse spectral data, yet key details such as the form of quantum catch used, whether photoreceptor adaptation was modelled, and the type of noise used in receptor-noise models were often not reported (Fig. 1).  The permanent, public storage of data also plays a pivotal role in reproducibility and transparency, yet public data storage in studies of colour traits is not yet the norm. It is increasingly difficult to justify the complete loss of data [@alsheikh_public_2011], and the benefits of publicly archiving data are considerable [@piwowar_sharing_2007; @vision_open_2010; @whitlock_data_2010]. 

Our objective in this paper was to highlight some important gaps that can influence the reproducibility of colour research, and to offer guidelines on simple ways in which studies may be leveraged to their full potential. By no means do we wish to say that studies lacking important details are not of significant value. We simply hope that our discussion of methods reporting and data archiving will contribute to the growing culture of reproducibility in science, and that researchers will consider these issues when deciding on the best practices in their work. It is only through critical appraisal and collegial discussion that we can identify areas for improvement, and constructively contribute to the growth of our field. Such assessments are particularly important in an age where accountability, transparency and reproducibility are at the forefront of discussions of the state of scientific research [@drew_lost_2013; @peng_reproducible_2011; @wicherts_willingness_2011]. We believe that part of the issue at hand is simply that researchers seldom have clear guidelines to follow when undertaking their research, and may overlook important aspects of methodology and analysis. We hope our critical evaluation of recent literature has highlighted a need for more careful descriptions of how colour traits are measured and analyzed. We are optimistic that this may help to establish uniform reporting guidelines for publication and increase transparency and reproducibility, which will continue the advance of an exciting era in colour research. 

## References