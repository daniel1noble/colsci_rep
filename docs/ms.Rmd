# Reproducible research in the study of biological colouration

Thomas E. White^2,6^, Rhiannon L. Dalrymple^1,6^, Daniel W. A. Noble^2,6^, James C. O’Hanlon ^2,6^, Daniel B. Zurek^5,6^, Kate D. L. Umbers^3,4,6^

^1^ Evolution & Ecology Research Centre, School of Biological, Earth and Environmental Sciences, University of New South Wales, Kensington, NSW, Australia, 2022 ^2^ Department of Biological Sciences, Macquarie University, North Ryde, NSW, Australia, 2109 ^3^ School of Biological Sciences, University of Wollongong, Wollongong, NSW, Austrlaia 2252 ^4^ Centre for Evolutionary Biology, University of Western Australia, Crawley, WA, Australia 6008 ^5^ Department of Biological Sciences, University of Pittsburgh, Pittsburgh, PA, USA, 15260

^6^ Authors contributed equally and are presented in random order

Corresponding Author:

Keywords: #colsci, spectrometry, photography, visual ecology, pigment, structural colour, visual modelling, methods 

Article type: Commentary

Word count:

Number of figures: 

Number of tables: 2

Data archiving:

\newpage

## Introduction

The study of colour in nature has generated insights into fundamental evolutionary and ecological processes, and research into colour traits is a rapidly growing field [@kelber_spectral_2010]. The resurgent interest in biological colouration has in large part been driven by the increased availability of key technologies, including spectrometry and photography, and concurrent advances in methods for analysing colour data, such as visual models [@endler_comparing_2005; @stevens_using_2007; @kelber_animal_2003]. While these developments are positive for the field, the increasingly complex analyses being run on ever greater amounts of data heighten the need for comprehensive methods reporting and proper data management [@alsheikh_public_2011; @nekrutenko_next_2012].      

Replication and transparency lie at the heart of the scientific enterprise. Beyond simply allowing the independent verification of results, reproducible research engenders greater comparability between studies and provides a foundation for the testing of new ideas and methods [@whitlock_data_2011; @van_trouble_2011; @piwowar_sharing_2007]. A study may be considered truly reproducible when it satisfies three broad criteria: (i) methods are reported completely, (ii) data are publicly available and archived, and (iii) analysis code is publicly available, such that the chain of modification of raw data is documented and preserved. While completely reproducible research [e.g. @fitzjohn_much_2014] is a laudable goal, the considerable demands it imposes on researchers means that it will often, in practice, be unattainable. Nevertheless, even partial reproducibility through the relatively simple practices of complete methods reporting and public data archiving is of tremendous value.     

Our aim here to explore the state of reproducibility in studies of biological colouration, and to outline ways in which it may be improved in line with points (i) - (iii) above. We begin by briefly outlining some of the most common methods for studying biological colouration, with an emphasis on the way in which their subtle complexity can shape results. We then present a set of guidelines for the comprehensive reporting of methods, and we analyse a subset of the literature against these criteria to assess the state of methods reporting in biological colour-science. We also assess the availability of publicly archived data and code, and suggest some useful tools for increasing the reproducibility of colour trait research more broadly.  

## Measuring colour

Generations of biologists have endeavoured to explain the mechanisms and functions of animal and plant colouration [@thayer_concealing_1909; @poulton_colours_1890; @wallace_natural_1891], and uncovering best practices in measuring colour has been a great challenge. The application of spectrometry to questions of biological colouration revolutionized the field [@dyck_determination_1966]. Now relatively inexpensive and convenient, spectrometry allows for the rapid capture of quantitative data, and has been widely adopted as a standard in the field [@andersson_quantifying_2006]. Digital photography is also increasingly being used to quantify biological colouration [@stevens_using_2007], as high-resolution cameras are inexpensive and allow for the rapid, repeatable sampling of multiple colour patches [@mckay_use_2013]. 

Subtle variation in the application of these common methods can significantly shape the resulting data. When using spectrometry, the angle from which spectra are collected [@santos_strong_2007], the calibration of light and dark standards, the distance between light source and surface, and the size, shape, glossiness or iridescence of the specimen will all directly affect the recorded spectra [@andersson_quantifying_2006; @kemp_ornamental_2008; @meadows_quantifying_2011; @schaefer_birds_2008]. The main challenge for gathering colour data from photographs is ensuring standardization against nonlinear responses to light intensity, biases towards particular wavebands, and inconsistent lighting [@stevens_using_2007]. Also, most digital cameras used for the measurement of biological colouration are consumer products designed for the human visual system. Thus hardware modifications for ultraviolet and infra-red imaging are often necessary [e.g. @stevens_colour_2013]. 

Expansion in the availability of objective methods for the measurement of colour has been matched by advances in theory and analysis. In particular, the development of visual models has enabled researchers to move beyond purely quantitative comparisons of reflectance spectra and adopt more biologically relevant perspectives when defining and testing hypotheses [@chittka_colour_1992; @endler_comparing_2005; @vorobyev_receptor_1998]. Visual models typically attempt to describe the reception and early-stage processing of colour information as a function of an object’s reflectance, the ambient illumination, and a receiver’s sensory system [e.g. @endler_comparing_2005; @vorobyev_receptor_1998]. Although relatively easy to implement, visual models are built on multiple assumptions about the way in which stimuli are processed that can dramatically shape the results of a given analysis [@lind_avian_2009; @pike_preserving_2012]. For example, Vorobyev et al.’s [-@vorobyev_receptor_1998; -@vorobyev_colour_2001] widely used receptor-noise model requires researchers to specify the form of receptor quantum catches (i.e. raw versus transformed), the use of any colour constancy mechanism (e.g. von Kries), as well as the photoreceptor signal-to-noise ratios, their relative densities, and the type of noise predominating (i.e. neural and/or receptor noise). These data are only available for a small number of species, such as humans and honeybees, and so assumptions and extrapolations are necessary when models are applied to other species. Unless the biological rationale underlying every parameter choice is clearly understood, justified, and reported, such analyses may become ineffective, especially when comparing results between studies [@pike_preserving_2012].  

Given the myriad degrees of freedom that exist when measuring and analysing colour, and the significant consequences of any variation, the conditions under which data were collected must be reported exactly....still working on this... Methods reporting should ideally have well defined standards such that sufficient detail is provided to allow comprehensive peer review, precise replication, cross-study comparison and data sharing [@alsheikh_public_2011; @sandve_ten_2013]....

## Assessing reproducibility

To assess the current state of reproducibility in the field we searched papers from 2013 in 22 leading journals: _American Journal of Botany_, _The American Naturalist_, _Animal Behaviour_, _Behavioral Ecology_, _Behavioral Ecology and Sociobiology_, _Biological Journal of the Linnean Society_, _Biology Letters_, _Current Zoology_, _Ecology_, _Ecology and Evolution_, _Ecology Letters_, _Ethology_, _Evolution_, _Functional Ecology_, _Journal of Ecology_, _The Journal of Evolutionary Biology_, _The Journal of Experimental Biology_, _Naturwissenschaften_, _New Phytologist_, _Oikos_, _PLoS ONE_, _Proceedings of the Royal Society B: Biological Sciences_. On each of the journals' homepages, we used the Boolean terms 'colour\*', 'color\*' or 'spectra\*' to search the title or abstract. We included only those papers that used either a spectrometer or camera to quantify colouration. We excluded review papers, methodological papers, papers quantifying colour patterns rather than the chromatic properties of a colour patch, and papers taking micro-spectrometric measurements of retinal absorbance. To review the large number of papers returned from our search, journals were haphazardly divided up between the authors. In order to reduce the risk of observer bias in our assessment, each paper was read and reassessed by three authors. Any discrepancies between assessor scores were discussed and resolved prior to analysis. We then tabulated what details of the methods were reported against our criteria. The data along with analysis script can be found on github (WHAT'S THE DOI?). We have kept the papers used in our dataset anonymous as our aim is to explore the general question of repeatability in the field. Our search returned a total of 216 papers, however, only `r nrow(coldat)` met our criteria and were included in the final analysis.

## Methods reporting in colour studies 

_Guidelines_

The comprehensive reporting of methods is the simplest step in ensuring research is reproducible. Accordingly, we developed a list of essential information about the capture (Table 1) and analysis (Table 2) of colour data that should ideally be reported. Given their overwhelming popularity, our data collection reporting guidelines are focused on spectrometry and photography for data collection (Table 1), and do not consider qualitative methods such as the use of Munsell chips or paint swatches. Analytical techniques are diverse and are being developed rapidly [@kelber_spectral_2010], and this rate of progress means that a deep understanding of common methods is increasingly beyond the grasp of the average researcher. As a consequence, the subtle complexity of many analytical techniques is often overlooked by empiricists, which leads to critical methodological information often not being reported. Our guidelines for reporting the details of colour analyses (Table 2) thus cover two broad, common categories of analysis: colourimetric (or 'spectral') analyses, and visual modelling. These tables present the framework for our subsequent analysis of methods reporting in the literature.  

_The current state of methods reporting in the literature_

Overall, `r specs+both` studies used a spectrometer to measure colour, while `r cam+both` used a camera. Of these studies, `r both` quantified colour using both a spectrometer and a camera. Reporting of the make and model of the spectrometer and camera was high (Figure 1, spectrometers = `r round(specModel, digits = 2)`% and cameras = `r round(camModel, digits = 2)`%), however, only `r round(propCam_fin["prop_light_source"], digits = 2)`%  and `r round(propSpec_fin["prop_light_source"], digits = 2)`% of camera and spectrometer studies reported a light source. In addition, the number of reflectance spectra and pixels averaged were only reported in `r round(propSpec_fin["prop_specpix_avg"], digits = 2)`% and `r round(propCam_fin["prop_specpix_avg"], digits = 2)`% of studies, respectively. Surprisingly, dark standards were only reported in `r round(propSpec_fin["prop_dark_std"], digits = 2)`% of the spectrometer studies, while white standards were reported in `r round(propSpec_fin["prop_white_stdspec"], digits = 2)`%. Studies quantifying spectral reflectance often did not report the integration time of the spectrophotmeter (`r round(propSpec_fin["prop_int_time"], digits = 2)`%), or the angle of the optical probe relative to the surface (`r round(propSpec_fin["prop_spec_angle"], digits = 2)`%) or distance (`r round(propSpec_fin["prop_spec_dist"], digits = 2)`%) the probe was held from the measurement surface. 
	
The types of analysis varied across studies. Overall `r analysisType[1]` papers generated colourimetric variables [i.e. 'spectral' measures of hue, saturation, and/or brightness; @montgomerie_analyzing_2006] whereas `r analysisType[4]` used visual models, `r analysisType[2]` used both colourimetrics and visual models, and `r analysisType[3]` used other forms of analysis (e.g. purely statistical analyses, such as principle component analysis on reflectance spectra). Of the studies quantifying colour using spectral reflectance curves `r analysisTypeSpec[1]` used colourimetric measures, `r analysisTypeSpec[2]` used multiple analyses, `r analysisTypeSpec[4]` used visual models and `r analysisTypeSpec[3]` used other forms of analysis. Studies using colourimetric measurements defined their measure of brightness, hue and/or chroma in `r round(col_def, digits = 2)`% of the studies. 

Most studies using visual models analysed their data using receptor-noise models (`r vismod_type[3]` of `r sum(vismod_type)` studies), while others used the colour hexagon (`r vismod_type[1]` studies), or a tetrahedral colour space (`r vismod_type[4]` studies). Case specific models were used in `r vismod_type[2]` papers. Of visual modelling papers, `r round(propSpec_fin["prop_irrad_type"], digits =2)`% reported the type of irradiance when necessary, `r round(propSpec_fin["prop_vis_mod_sp"], digits = 2)`% the species modelled as a receiver. The background used in visual models was reported `r round(propSpec_fin["prop_vis_mod_bkg"], digits = 2)`% of the time. The type of receptor noise modelled was reported in only `r round(propSpec_fin["prop_vis_mod_noise_type"], digits = 2)`% of the studies. Explicit mention of the type of quantum catch (`r round(propSpec_fin["prop_vis_mod_qcatch"], digits = 2)`% of studies), or whether photoreceptor adaptation (`r round(propSpec_fin["prop_vis_mod_adapt"], digits = 2)`%) was modelled, was not common. 

While some of the percentages reported above seem alarming, it is important to note that around one-third of papers (`r round(ref_stud, digits = 2)`%) made reference to previous work for various methods. This means that our above figures are slightly liberal given that the referenced works may have comprehensively covered some of these criteria. Despite this, two-thirds of the studies did not reference previous work, and were missing important methodological details, suggesting the need for more comprehensive reporting of methods...touch more discussion here, instead of in conclusions(?)...e.g...When possible, we also recommend that authors also justify data capture and analytical approaches - something few studies we investigated explicitly outlined.

## The public availability of data and code

Of the `r nrow(coldat)` studies analysed, `r round((data["raw"]/sum(data))*100, digits = 2)`% publicly provided the raw underlying data, `round((data["proc"]/sum(data))*100, digits = 2)`% provided data in a pre-processed form, and `r round((data["none"]/sum(data))*100, digits = 2)`% of studies did not provide any publicly accessible data. The paucity of data being made available post-publication in studies of biological colouration is in line with other fields [@drew_lost_2013; @vines_mandated_2013; @wolkovich_advances_2012], including the broader field of animal behaviour [@caetano_forgotten_2014]. There is evidence, however, that this trend is shifting as funders and journals increasingly mandate the release of data [@whitlock_data_2010]. The clearest benefit of open access to data is that it allows researchers to build upon previous work for the testing and refinement of new ideas and methods. This is particularly relevant in the study of colour traits, where new methods for analysing colour data are regularly developed [e.g. @allen_analyzing_2013; @endler_framework_2012; @stoddard_pattern_2014]. The provision of open data may also foster collaborations as researchers draw upon existing work [@whitlock_data_2011], and increased data sharing has been shown to positively correlate with citations [@piwowar_sharing_2007]. Given the increasing rate of retractions, there is also impetus for researchers to maintain credibility through transparency [@steen_retractions_2010; @van_trouble_2011; @wicherts_willingness_2011]. We thus encourage researchers to publicly archive data in as raw a form as possible (e.g. individual reflectance spectra), to maximise its utility. Public data repositories such as figshare (REF?) and dryad (REF?) facilitate the permanent archival of data as citable research objects, and the preparation of data for publication is often straightforward [@whitlock_data_2011]. The use of modest data embargoes and appropriate licenses can help to ensure that original authors are able to make the best use of data, and are subsequently credited [though we acknowledge that tensions over data-sharing exist; discussed in @roche_troubleshooting_2014].
 
None of the included studies linked to any form of code, which is not surprising given the popularity of graphical-user-interface (GUI) based statistical, and colour-analytical software [e.g. AVICOL; @gomez_avicol_2006]. Here we simply note that there are several advantages to moving from a GUI-based to a programming workflow, in spite of the initial time investment required. The open-source programming language R [@R_program], for example, is free and is host to a sizeable community of developers that build and implement analytical tools (via 'packages'). Indeed, packages specifically for the analysis of colour data already exist [e.g. pavo; @maia_pavo_2013]. Perhaps the most significant advantage is that analysis scripts produced in such a way represent a complete documented history of a study's analytical methods. For authors this means that the details of a study's methods may be precisely preserved, and it allows other researchers to directly build upon.....

........greater speed and better control...documenting of methods & maintaining chain of modification for reproducibility...something about git facilitating collaboration & project management [@ram_git_2013]. Maybe rmarkdown [@rmarkdown]

## Conclusions

Our review of the recent colour literature highlights some significant impediments to reproducibility. The simplest step towards reproducible research is through the comprehensive reporting of methods, yet crucial methodological information is often unreported (Fig. 1). In particular, we found that the types of light sources, numbers of pixels or spectra averaged, the distance and angle of the spectrometers optical probe relative to the measurement surface and collector, and types of standards used (i.e. white and black reference samples) are under-reported (Fig. 1). Visual models were regularly used to analyse spectral data, yet key details such as the form of quantum catch used, whether photoreceptor adaptation was modelled, and the type of noise used in receptor-noise models were often not reported (Fig. 1). 

The permanent, private storage of data [or, more often, the complete loss of data; @alsheikh_public_2011] is increasingly difficult to justify, and the benefits of publicly archived data are considerable [@piwowar_sharing_2007; @vision_open_2010; @whitlock_data_2010]. Most of the data underlying studies of biological colouration are unpublished, and are thus likely to be lost... 

The move towards increasingly reproducible research has many benefits. Our objective in this paper was to explore the issue of reproducibility in studies of biological colouration, and to offer guidelines on simple ways in which studies may be leveraged to their full potential. We hope our that our discussion of methods reporting and data archiving will contribute to the growing culture of reproducibility in science, and that researchers will consider these issues when deciding on the best practices in their work. The future of colour-trait research is bright (obligatory pun?!)...something something maybe...continuing the advance of an exciting field. 

## References